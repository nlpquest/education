{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\npd.set_option(\"display.max_rows\", 300)\nimport random\nimport string\nfrom collections import defaultdict\nfrom tqdm import tqdm \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten, Conv2D, MaxPooling2D, Input, concatenate\nfrom tensorflow.keras.utils import to_categorical, plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-12T17:31:18.334827Z","iopub.execute_input":"2023-02-12T17:31:18.335244Z","iopub.status.idle":"2023-02-12T17:31:25.403295Z","shell.execute_reply.started":"2023-02-12T17:31:18.335208Z","shell.execute_reply":"2023-02-12T17:31:25.401979Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"execution":{"iopub.status.busy":"2023-01-10T00:14:42.982003Z","iopub.execute_input":"2023-01-10T00:14:42.982699Z","iopub.status.idle":"2023-01-10T00:14:48.859944Z","shell.execute_reply.started":"2023-01-10T00:14:42.982660Z","shell.execute_reply":"2023-01-10T00:14:48.858863Z"}}},{"cell_type":"markdown","source":"First, we build a contrived dataset for text-classification. We will create random string texts with 30 up to 50 characters from all ascii letters, digits and punctuations. As we want to build a binary classification problem, we have to create 0's and 1's. We insert the letters [\"A\", \"B\", \"C\"] in order of apperance randomly in the generate text, as a sign of label being 0. And we insert letters of [\"D\", \"E\", \"F\"]. This pattern won't be perfectlz distinguishable because these letters can appear in other parts of the string as well, but we don't want it to be perfect either as it is natural for the dataset to have some noise too.","metadata":{}},{"cell_type":"code","source":"def generate_text(label):\n    text = ''.join([random.choice(string.ascii_letters + string.digits + string.punctuation ) \n                    for _ in range(random.randint(30, 50))]) \n    \n    if label==0:\n        characters = [\"A\", \"B\", \"C\"]\n    elif label==1:\n        characters = [\"D\", \"E\", \"F\"]\n    indices = sorted(random.choices(list(range(len(text))), k=3))\n    return  (text[:indices[0]] + characters[0] + text[indices[0]:indices[1]] + characters[1] +\n        text[indices[1]:indices[2]] + characters[2] + text[indices[2]:] )\n    \n\ndf_len = 1400\ndf = pd.DataFrame(columns=[\"text\", \"label\"])\ndf[\"label\"] = [0] * int(df_len/2) + [1] * int(df_len/2)\ndf[\"text\"] = df[\"label\"].apply(lambda row: generate_text(row))\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-12T17:31:41.080535Z","iopub.execute_input":"2023-02-12T17:31:41.082049Z","iopub.status.idle":"2023-02-12T17:31:41.213799Z","shell.execute_reply.started":"2023-02-12T17:31:41.081990Z","shell.execute_reply":"2023-02-12T17:31:41.212543Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                               text  label\n0               nHx^P(~i_=SlAhB@(lWn2y3}KehuVqPF~C\\      0\n1  AtOB-l8sb;2V'-xa<16\\|U)*~b8#1[4pcy}(4ZC\\.cCN\"1mn      0\n2              Wyo]4rqH[HSj)Y|!FbA*syMcwNy=B:lU.C40      0\n3         A}J=Z<zmryB`Cm.#y/PI5J=f^N1lgZHt=wj:syD*L      0\n4             yr7k}>}]AK!j$AiPgj:B.=!<CLP09t;RE80Q{      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nHx^P(~i_=SlAhB@(lWn2y3}KehuVqPF~C\\</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AtOB-l8sb;2V'-xa&lt;16\\|U)*~b8#1[4pcy}(4ZC\\.cCN\"1mn</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wyo]4rqH[HSj)Y|!FbA*syMcwNy=B:lU.C40</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A}J=Z&lt;zmryB`Cm.#y/PI5J=f^N1lgZHt=wj:syD*L</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>yr7k}&gt;}]AK!j$AiPgj:B.=!&lt;CLP09t;RE80Q{</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = df[200:-200].copy()\nval = pd.concat([df[:100],  df[-100:]], axis=0).copy()\ntest = pd.concat([df[100:200], df[-200:-100]], axis=0).copy()\n\nprint(len(train), len(val), len(test))","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:37:57.209508Z","iopub.execute_input":"2023-01-10T15:37:57.209923Z","iopub.status.idle":"2023-01-10T15:37:57.222133Z","shell.execute_reply.started":"2023-01-10T15:37:57.209890Z","shell.execute_reply":"2023-01-10T15:37:57.220475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocabulary = defaultdict(int)\n\nfor i in tqdm(range(len(train))):\n    characters = train[\"text\"].iloc[i]\n    for ch in characters:\n        vocabulary[ch] += 1\n        \nfor i, (k, w) in enumerate(vocabulary.items(), start=1):\n    vocabulary[k] = [w, i]\n    \nprint(len(vocabulary))","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:37:58.035240Z","iopub.execute_input":"2023-01-10T15:37:58.036583Z","iopub.status.idle":"2023-01-10T15:37:58.071956Z","shell.execute_reply.started":"2023-01-10T15:37:58.036529Z","shell.execute_reply":"2023-01-10T15:37:58.070279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data","metadata":{"execution":{"iopub.status.busy":"2023-01-10T11:34:51.875264Z","iopub.execute_input":"2023-01-10T11:34:51.875586Z","iopub.status.idle":"2023-01-10T11:34:51.881131Z","shell.execute_reply.started":"2023-01-10T11:34:51.875556Z","shell.execute_reply":"2023-01-10T11:34:51.880004Z"}}},{"cell_type":"code","source":"def func(row):\n    output = []\n    for ch in row:\n        if vocabulary[ch]:\n            output.append(vocabulary[ch][1])\n    return output \n\ntrain[\"text_int_encoded\"] = train[\"text\"].apply(lambda row: func(row))\ntrain[\"text_len\"] = train[\"text\"].apply(len)\nmax_seq_len = train[\"text_len\"].max()\nprint(\"max seq len:\", max_seq_len)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:00.456754Z","iopub.execute_input":"2023-01-10T15:38:00.457158Z","iopub.status.idle":"2023-01-10T15:38:00.479882Z","shell.execute_reply.started":"2023-01-10T15:38:00.457120Z","shell.execute_reply":"2023-01-10T15:38:00.478592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:05.448861Z","iopub.execute_input":"2023-01-10T15:38:05.449289Z","iopub.status.idle":"2023-01-10T15:38:05.461992Z","shell.execute_reply.started":"2023-01-10T15:38:05.449252Z","shell.execute_reply":"2023-01-10T15:38:05.460961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val[\"text_int_encoded\"] = val[\"text\"].apply(lambda row: func(row))\nval[\"text_len\"] = val[\"text\"].apply(len)\n\ntest[\"text_int_encoded\"] = test[\"text\"].apply(lambda row: func(row))\ntest[\"text_len\"] = test[\"text\"].apply(len)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:06.923894Z","iopub.execute_input":"2023-01-10T15:38:06.924884Z","iopub.status.idle":"2023-01-10T15:38:06.942143Z","shell.execute_reply.started":"2023-01-10T15:38:06.924835Z","shell.execute_reply":"2023-01-10T15:38:06.940877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model based on integer encoding","metadata":{}},{"cell_type":"code","source":"def pad(row, max_seq_len):\n    if len(row) < max_seq_len:\n        return row + [0] * (max_seq_len - len(row))\n    else:\n        return row[:max_seq_len]\n\ntrain[\"text_int_encoded_padded\"] = train[\"text_int_encoded\"].apply(lambda row: pad(row, max_seq_len))\nval[\"text_int_encoded_padded\"] = val[\"text_int_encoded\"].apply(lambda row: pad(row, max_seq_len))\ntest[\"text_int_encoded_padded\"] = test[\"text_int_encoded\"].apply(lambda row: pad(row, max_seq_len))","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:09.107853Z","iopub.execute_input":"2023-01-10T15:38:09.108265Z","iopub.status.idle":"2023-01-10T15:38:09.122905Z","shell.execute_reply.started":"2023-01-10T15:38:09.108216Z","shell.execute_reply":"2023-01-10T15:38:09.121550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_int = np.stack(np.array(train[\"text_int_encoded_padded\"].iloc[i]) for i in range(len(train)))\ny_train = train[\"label\"]\n\nx_val_int = np.stack(np.array(val[\"text_int_encoded_padded\"].iloc[i]) for i in range(len(val)))\ny_val = val[\"label\"]\n\nx_test_int = np.stack(np.array(test[\"text_int_encoded_padded\"].iloc[i]) for i in range(len(test)))\ny_test = test[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:11.043112Z","iopub.execute_input":"2023-01-10T15:38:11.043523Z","iopub.status.idle":"2023-01-10T15:38:11.081756Z","shell.execute_reply.started":"2023-01-10T15:38:11.043482Z","shell.execute_reply":"2023-01-10T15:38:11.080448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nn_model_int_encoded(seq_len: int):\n    kernel= 'normal'\n    model= Sequential(name='sequential')\n    model.add(Dense(200, input_dim=seq_len, kernel_initializer=kernel, activation='relu', name='dense_1'))\n    model.add(Dropout(0.4,name='dropout_0'))\n    model.add(Dense(100, kernel_initializer=kernel, activation='relu', name='dense_2'))\n    model.add(Dropout(0.4,name='dropout_1'))\n    model.add(Dense(50, kernel_initializer=kernel, activation='relu', name='dense_3'))\n    model.add(Dropout(0.4,name='dropout_2'))\n    model.add(Dense(1, kernel_initializer=kernel, activation='sigmoid', name='dense_4'))\n    \n    # compile\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model   ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:38:12.349930Z","iopub.execute_input":"2023-01-10T15:38:12.350324Z","iopub.status.idle":"2023-01-10T15:38:12.360084Z","shell.execute_reply.started":"2023-01-10T15:38:12.350290Z","shell.execute_reply":"2023-01-10T15:38:12.358511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_int_encoded = nn_model_int_encoded(seq_len=max_seq_len)\nhistory = model_int_encoded.fit(x_train_int, y_train, \n                   validation_data=(x_val_int, y_val), \n                   batch_size=16,\n                   epochs=200)\nplt.plot(history.history['accuracy'], label=\"train_accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.title('nn_model_int_encoded')\nplt.legend()\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:39:11.242999Z","iopub.execute_input":"2023-01-10T15:39:11.243401Z","iopub.status.idle":"2023-01-10T15:40:09.148867Z","shell.execute_reply.started":"2023-01-10T15:39:11.243370Z","shell.execute_reply":"2023-01-10T15:40:09.147056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_int_predicted = model_int_encoded.predict(x_test_int)\ny_int_predicted = (y_int_predicted > 0.5).astype(\"int32\").ravel()\ntest_acc = accuracy_score(y_test, y_int_predicted)\nprint(\"test accuracy: \", test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:58:14.011549Z","iopub.execute_input":"2023-01-10T15:58:14.011954Z","iopub.status.idle":"2023-01-10T15:58:14.091220Z","shell.execute_reply.started":"2023-01-10T15:58:14.011924Z","shell.execute_reply":"2023-01-10T15:58:14.089859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model based on one-hot encoding","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:43:46.256056Z","iopub.execute_input":"2023-01-10T15:43:46.256565Z","iopub.status.idle":"2023-01-10T15:43:46.278200Z","shell.execute_reply.started":"2023-01-10T15:43:46.256525Z","shell.execute_reply":"2023-01-10T15:43:46.276598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_categorical(train[\"text_int_encoded_padded\"].iloc[0], num_classes=(len(vocabulary)+1)).ravel()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:45:01.267799Z","iopub.execute_input":"2023-01-10T15:45:01.268187Z","iopub.status.idle":"2023-01-10T15:45:01.277298Z","shell.execute_reply.started":"2023-01-10T15:45:01.268158Z","shell.execute_reply":"2023-01-10T15:45:01.276199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_onehot = np.stack(\n    to_categorical(train[\"text_int_encoded_padded\"].iloc[i], num_classes=(len(vocabulary)+1)).ravel() for i in range(len(train))\n)\nx_val_onehot = np.stack(\n    to_categorical(val[\"text_int_encoded_padded\"].iloc[i], num_classes=(len(vocabulary)+1)).ravel() for i in range(len(val))\n)\nx_test_onehot = np.stack(\n    to_categorical(test[\"text_int_encoded_padded\"].iloc[i], num_classes=(len(vocabulary)+1)).ravel() for i in range(len(test))\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:59:50.084814Z","iopub.execute_input":"2023-01-10T15:59:50.085275Z","iopub.status.idle":"2023-01-10T15:59:50.164985Z","shell.execute_reply.started":"2023-01-10T15:59:50.085240Z","shell.execute_reply":"2023-01-10T15:59:50.163924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"text_int_encoded\"].apply(len).max()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:31:27.553185Z","iopub.execute_input":"2023-01-10T15:31:27.553575Z","iopub.status.idle":"2023-01-10T15:31:27.561961Z","shell.execute_reply.started":"2023-01-10T15:31:27.553544Z","shell.execute_reply":"2023-01-10T15:31:27.560780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nn_model_onehot_encoded(seq_len: int):\n    kernel= 'normal'\n    model= Sequential(name='sequential')\n    model.add(Dense(5000, input_dim=seq_len*(len(vocabulary)+1), kernel_initializer=kernel, activation='relu', name='dense_1'))\n    model.add(Dropout(0.5,name='dropout_0'))\n    model.add(Dense(2500, kernel_initializer=kernel, activation='relu', name='dense_2'))\n    model.add(Dropout(0.5,name='dropout_1'))\n    model.add(Dense(1250, kernel_initializer=kernel, activation='relu', name='dense_3'))\n    model.add(Dropout(0.5,name='dropout_2'))\n    model.add(Dense(1, kernel_initializer=kernel, activation='sigmoid', name='dense_4'))\n    \n    # compile\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model  \n\nmodel_onehot_encoded = nn_model_onehot_encoded(seq_len=max_seq_len)\nes = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\nhistory = model_onehot_encoded.fit(x_train_onehot, y_train, \n                   validation_data=(x_val_onehot, y_val), \n                   batch_size=16,\n                   epochs=10,\n                   callbacks=[es])\nplt.plot(history.history['accuracy'], label=\"train_accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.title('nn_model_onehot_encoded')\nplt.legend()\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:17:13.259753Z","iopub.execute_input":"2023-01-10T16:17:13.260151Z","iopub.status.idle":"2023-01-10T16:18:36.800663Z","shell.execute_reply.started":"2023-01-10T16:17:13.260120Z","shell.execute_reply":"2023-01-10T16:18:36.798873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_onehot_predicted = model_onehot_encoded.predict(x_test_onehot)\ny_onehot_predicted = (y_onehot_predicted > 0.5).astype(\"int32\").ravel()\ntest_acc = accuracy_score(y_test, y_onehot_predicted)\nprint(\"test accuracy: \", test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:19:00.696774Z","iopub.execute_input":"2023-01-10T16:19:00.697213Z","iopub.status.idle":"2023-01-10T16:19:01.062671Z","shell.execute_reply.started":"2023-01-10T16:19:00.697180Z","shell.execute_reply":"2023-01-10T16:19:01.061300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model based on embeddings","metadata":{}},{"cell_type":"code","source":"train.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:19:29.466928Z","iopub.execute_input":"2023-01-10T16:19:29.467374Z","iopub.status.idle":"2023-01-10T16:19:29.483872Z","shell.execute_reply.started":"2023-01-10T16:19:29.467339Z","shell.execute_reply":"2023-01-10T16:19:29.482440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nn_model_embedding(seq_len: int):\n    kernel= 'normal'\n    model= Sequential(name='sequential')\n    model.add(Embedding(input_dim=(len(vocabulary)+1), output_dim=15, input_length=seq_len, name='embedding'))\n    model.add(Flatten(name=\"flatten\"))\n    model.add(Dense(500, kernel_initializer=kernel, activation='relu', name='dense_1'))\n    model.add(Dropout(0.5,name='dropout_0'))\n    #model.add(Dense(500, kernel_initializer=kernel, activation='relu', name='dense_2'))\n    #model.add(Dropout(0.5,name='dropout_1'))\n    #model.add(Dense(250, kernel_initializer=kernel, activation='relu', name='dense_3'))\n    #model.add(Dropout(0.5,name='dropout_2'))\n    model.add(Dense(1, kernel_initializer=kernel, activation='sigmoid', name='dense_4'))\n    \n    opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n    # compile\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    plot_model(model, show_shapes= True, to_file= 'nn_embedding.png')\n    \n    return model  \n\n\nmodel_embedding = nn_model_embedding(seq_len=max_seq_len)\nnum_epochs = 25\nes = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=num_epochs, restore_best_weights=True)\nhistory = model_embedding.fit(x_train_int, y_train, \n                   validation_data=(x_val_int, y_val), \n                   batch_size=16,\n                   epochs=num_epochs,\n                   callbacks=[es])\nplt.plot(history.history['accuracy'], label=\"train_accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.title('nn_model_embedding')\nplt.legend()\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:08:16.499205Z","iopub.execute_input":"2023-01-10T17:08:16.499620Z","iopub.status.idle":"2023-01-10T17:08:26.717148Z","shell.execute_reply.started":"2023-01-10T17:08:16.499587Z","shell.execute_reply":"2023-01-10T17:08:26.715790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_embedding_predicted = model_embedding.predict(x_test_int)\ny_embedding_predicted = (y_embedding_predicted > 0.5).astype(\"int32\").ravel()\ntest_acc = accuracy_score(y_test, y_embedding_predicted)\nprint(\"test accuracy: \", test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:08:28.982925Z","iopub.execute_input":"2023-01-10T17:08:28.983358Z","iopub.status.idle":"2023-01-10T17:08:29.112343Z","shell.execute_reply.started":"2023-01-10T17:08:28.983321Z","shell.execute_reply":"2023-01-10T17:08:29.111435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MC-CNN","metadata":{}},{"cell_type":"code","source":"CHANNELS = [2, 3, 4, 5]\n\ndef mccnn_model(timesteps: int, \n              vocab_size: int) -> Model:\n\n    embedding_size = 15\n    \n    # the multichannel part\n    inputs = list()\n    flats = list()\n    \n    for i, ks in enumerate(CHANNELS):\n        input_ = Input(shape=(timesteps, 1), name=f'input_{i}')\n        embedding = Embedding(vocab_size, embedding_size, name=f'embedding_{i}') (input_)\n        \n        conv_one = Conv2D(filters=256, kernel_size=(ks, embedding_size),\n                         padding='same', activation='relu', name=f'conv_one_{i}')(embedding)\n        drop_one = Dropout(0.5, name=f'dropout_one_{i}')(conv_one)\n        pool_one = MaxPooling2D(pool_size=(timesteps-ks+1, 1), name=f'pooling_one_{i}')(drop_one)\n        \n        flat = Flatten(name=f'flatten_{i}')(pool_one)\n        \n        inputs.append(input_)\n        flats.append(flat)\n        \n    merged= concatenate(flats, name='merged')\n    # The dense layers part\n    dense1 = Dense(512, activation='relu', name='dense_1')(merged)\n    drop1 = Dropout(0.5, name='dropout_1')(dense1)\n    dense2 = Dense(256, activation='relu', name='dense_2')(drop1)\n    drop2 = Dropout(0.5, name='dropout_2')(dense2)\n    dense3 = Dense(1, activation='sigmoid', name='dense_3') (drop2)\n    \n    # build the model\n    model = Model(inputs=inputs, outputs=dense3)\n    \n    # compile\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #model.sumamry()\n    plot_model(model, show_shapes=True, to_file='multichannel_cnn.png')\n    return model\n################################################\nmodel_mccnn = mccnn_model(timesteps=max_seq_len, vocab_size=(len(vocabulary)+1))\nnum_epochs = 25\nes = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=num_epochs, restore_best_weights=True)\nhistory = model_mccnn.fit([x_train_int]*len(CHANNELS), y_train, \n                   validation_data=([x_val_int]*len(CHANNELS), y_val), \n                   batch_size=16,\n                   epochs=num_epochs,\n                   callbacks=[es])\nplt.plot(history.history['accuracy'], label=\"train_accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.title('nn_model_embedding')\nplt.legend()\nplt.show()\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:33:42.361323Z","iopub.execute_input":"2023-01-10T17:33:42.361771Z","iopub.status.idle":"2023-01-10T17:35:46.817700Z","shell.execute_reply.started":"2023-01-10T17:33:42.361735Z","shell.execute_reply":"2023-01-10T17:35:46.816114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mccnn_predicted = model_mccnn.predict([x_test_int]*len(CHANNELS))\ny_mccnn_predicted = (y_mccnn_predicted > 0.5).astype(\"int32\").ravel()\ntest_acc = accuracy_score(y_test, y_mccnn_predicted)\nprint(\"test accuracy: \", test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:35:46.820569Z","iopub.execute_input":"2023-01-10T17:35:46.821759Z","iopub.status.idle":"2023-01-10T17:35:47.279785Z","shell.execute_reply.started":"2023-01-10T17:35:46.821684Z","shell.execute_reply":"2023-01-10T17:35:47.278884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}